{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64fa8dda-5378-4a9a-989a-3b247e6d9380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98b242d7-7784-4a7c-a8bf-f336e90b8fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'images/train'\n",
    "TEST_DIR = 'images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b336d3f-e4d6-4dee-bf60-d5a52ebb6c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdataframe(dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        for imagename in os.listdir(os.path.join(dir,label)):\n",
    "            image_paths.append(os.path.join(dir,label,imagename))\n",
    "            labels.append(label)\n",
    "        print(label, \"completed\")\n",
    "    return image_paths,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23cbea66-a04e-42d3-aa66-e9ea49ba9226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame()\n",
    "train['image'], train['label'] = createdataframe(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19a2e4f7-6aea-47f1-9181-f0a37f4ce812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                image     label\n",
      "0            images/train\\angry\\0.jpg     angry\n",
      "1            images/train\\angry\\1.jpg     angry\n",
      "2           images/train\\angry\\10.jpg     angry\n",
      "3        images/train\\angry\\10002.jpg     angry\n",
      "4        images/train\\angry\\10016.jpg     angry\n",
      "...                               ...       ...\n",
      "28816  images/train\\surprise\\9969.jpg  surprise\n",
      "28817  images/train\\surprise\\9985.jpg  surprise\n",
      "28818  images/train\\surprise\\9990.jpg  surprise\n",
      "28819  images/train\\surprise\\9992.jpg  surprise\n",
      "28820  images/train\\surprise\\9996.jpg  surprise\n",
      "\n",
      "[28821 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee6f1b1b-216f-4d31-a159-c935349d55c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n"
     ]
    }
   ],
   "source": [
    "test = pd.DataFrame()\n",
    "test['image'], test['label'] = createdataframe(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa51315b-e6f2-4e3b-9f3b-7506de5c62fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              image     label\n",
      "0       images/test\\angry\\10052.jpg     angry\n",
      "1       images/test\\angry\\10065.jpg     angry\n",
      "2       images/test\\angry\\10079.jpg     angry\n",
      "3       images/test\\angry\\10095.jpg     angry\n",
      "4       images/test\\angry\\10121.jpg     angry\n",
      "...                             ...       ...\n",
      "7061  images/test\\surprise\\9806.jpg  surprise\n",
      "7062  images/test\\surprise\\9830.jpg  surprise\n",
      "7063  images/test\\surprise\\9853.jpg  surprise\n",
      "7064  images/test\\surprise\\9878.jpg  surprise\n",
      "7065   images/test\\surprise\\993.jpg  surprise\n",
      "\n",
      "[7066 rows x 2 columns]\n",
      "0         images/test\\angry\\10052.jpg\n",
      "1         images/test\\angry\\10065.jpg\n",
      "2         images/test\\angry\\10079.jpg\n",
      "3         images/test\\angry\\10095.jpg\n",
      "4         images/test\\angry\\10121.jpg\n",
      "                    ...              \n",
      "7061    images/test\\surprise\\9806.jpg\n",
      "7062    images/test\\surprise\\9830.jpg\n",
      "7063    images/test\\surprise\\9853.jpg\n",
      "7064    images/test\\surprise\\9878.jpg\n",
      "7065     images/test\\surprise\\993.jpg\n",
      "Name: image, Length: 7066, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(test)\n",
    "print(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d8bf0be-65ab-4aa1-bdda-e3fa2b0356aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d97aa89c-f4c4-4fe1-9271-1cb9dec9107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images):\n",
    "    features = []\n",
    "    for image in tqdm(images):\n",
    "        img = load_img(image,grayscale =  True )\n",
    "        img = np.array(img)\n",
    "        features.append(img)\n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features),48,48,1)\n",
    "    return features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "201a189b-bd53-439f-9ec7-8921c2f2c785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4bf708be241455993a66fe43152dfc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras_preprocessing\\image\\utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    }
   ],
   "source": [
    "train_features = extract_features(train['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfe5e549-a4e7-462c-88ad-59b2ac10f447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16496229cdda433aa7b099d7f08b5acf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7066 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_features = extract_features(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18dd0deb-fe6c-4498-8728-9703b5709e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_features/255.0\n",
    "x_test = test_features/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bbf8275-76f5-4805-ab2c-21725147e604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1d4f547-6d9a-44b6-a420-2b8c47d143c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LabelEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.preprocessing.LabelEncoder.html\">?<span>Documentation for LabelEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78dce075-ecbb-448e-b8cd-0893cfb8a92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = le.transform(train['label'])\n",
    "y_test = le.transform(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cda98a4d-83bc-4ed0-a963-c37f0e5a3bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,num_classes = 7)\n",
    "y_test = to_categorical(y_test,num_classes = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eaf21757-410c-4b27-99f5-e709e7e84c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python313\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# convolutional layers\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "# fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# output layer\n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67ba3882-5519-404c-b98e-192b872d4405",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ed1d8db-dc15-46c8-b632-8063ddf64334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 1s/step - accuracy: 0.2433 - loss: 1.8205 - val_accuracy: 0.2586 - val_loss: 1.7915\n",
      "Epoch 2/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 2s/step - accuracy: 0.2899 - loss: 1.7297 - val_accuracy: 0.3748 - val_loss: 1.6261\n",
      "Epoch 3/100\n",
      "\u001b[1m 33/226\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:02\u001b[0m 946ms/step - accuracy: 0.3544 - loss: 1.6267"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model.fit(x= x_train,y = y_train, batch_size = 128, epochs = 100, validation_data = (x_test,y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c77b576b-0007-464b-a36e-a78f0961ed22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"emotiondetector.json\",'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save(\"emotiondetector.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d332229a-8d91-4c74-b756-343b1afd86d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "17d0e1d4-5e17-422f-a449-0a4d5b0259de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python313\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "json_file = open(\"facialemotionmodel.json\", \"r\")\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights(\"facialemotionmodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb520a89-32b7-4da5-9c1d-4096ea57d984",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['angry','disgust','fear','happy','neutral','sad','surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3b67a45e-2b47-4e84-ac04-9de34ecdf2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ef(image):\n",
    "    img = load_img(image,grayscale =  True )\n",
    "    feature = np.array(img)\n",
    "    feature = feature.reshape(1,48,48,1)\n",
    "    return feature/255.0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "09bb7686-0778-48c0-b83e-5f9bf02c3de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image is of sad\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545ms/step\n",
      "model prediction is  sad\n"
     ]
    }
   ],
   "source": [
    "image = 'images/train/sad/42.jpg'\n",
    "print(\"original image is of sad\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ac179b-a84e-4499-8c93-c29d79f50cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "48268054-dcfa-4e1b-b275-33eede42af89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image is of sad\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
      "model prediction is  sad\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a00e2e0050>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = 'images/train/sad/42.jpg'\n",
    "print(\"original image is of sad\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9538d58f-6bca-41c5-8870-58c26d8632e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
